#!/bin/bash
#===============================================================================
#
#  Main settings for SCALE-LETKF scripts
#
#===============================================================================

PRESET='FUGAKU'

#===============================================================================

DIR="$(cd "$(pwd)/.." && pwd)"    # Root directory of the SCALE-LETKF

OUTDIR=/data/${GROUP}/$(id -nu)/test_scale/result/PAWR_Kobe ### EDIT HERE ### 
INDIR=$OUTDIR

#===============================================================================
# Location of model/data files

SCALEDIR="$DIR/../.."                  # Directory of the SCALE model
DATADIR=$SCALE_DB  # Directory of the SCALE database

DATA_BDY_SCALE=$DATADIR/scale-letkf-test-suite/exp/PAWR_Kobe_bdy # Directory of the boundary data in SCALE history format (parent domain)
DATA_TOPO_BDY_SCALE=$DATA_BDY_SCALE
DATA_TOPO=$INDIR                                # Directory of the prepared topo files
DATA_LANDUSE=$DATA_TOPO                         # Directory of the prepared landuse files
DATA_BDY_SCALE_PRC_NUM_X=4
DATA_BDY_SCALE_PRC_NUM_Y=2
DATA_BDY_SCALE_PREP=         # Directory of the prepared SCALE boundary files
DATA_BDY_WRF=                # Directory of the boundary data in WRF format
DATA_BDY_NICAM=              # Directory of the boundary data in NICAM format (not finished)

DATA_BDY_GRADS=

OBS=$DATADIR/scale-letkf-test-suite/obs/PAWR_Kobe

#===============================================================================
# model/data file options

DET_RUN=0               # 0: Disable the deterministic run
                        # 1: Enable  the deterministic run

#TOPO_FORMAT='prep'     # 'prep': Use prepared topo files in $DATA_TOPO
TOPO_FORMAT='DEM50M'    # 'prep': Use prepared topo files in $DATA_TOPO
                        # 'GTOPO30' (requires compatible 'config.nml.scale_pp')
                        # 'DEM50M'  (requires compatible 'config.nml.scale_pp')

#LANDUSE_FORMAT='prep'   # 'prep': Use prepared landuse files in $DATA_LANDUSE
LANDUSE_FORMAT='LU100M'  # 'prep': Use prepared landuse files in $DATA_LANDUSE
                        # 'GLCCv2' (requires compatible 'config.nml.scale_pp')
                        # 'LU100M' (requires compatible 'config.nml.scale_pp')
LANDUSE_UPDATE=0        # 0: Time-invariant landuse files
                        # 1: Time-variant landuse files

BDY_FORMAT=1            # 0: SCALE boundary files (with exactly same domain settings; do not need additional preprocessing)
                        # 1: SCALE history (requires compatible 'config.nml.scale_init')
                        # 2: WRF           (requires compatible 'config.nml.scale_init')
                        # 3: NICAM         (requires compatible 'config.nml.scale_init')
                        # 4: GrADS         (requires compatible 'config.nml.scale_init')
BDY_SINGLE_FILE=0       # 0: Length of a boundary file = $BDYCYCLE_INT (e.g., files made by data assimilation cycles)
                        # 1: Length of a boundary file is long enough so that only a single boundary file is used for each forecast
BDY_SCALE_DIR='fcst'    # Directory name of the SCALE history files when $BDY_FORMAT = 1

BDY_ENS=1               # 0: Fixed boundary files for all memebers
                        # 1: Ensemble boundary files

# FCST
BDY_ROTATING=0          # 0: Use a same series of boundary files for all initial time
                        # 1: Use different series of boundary files for different initial time


BDYINT=600
BDYCYCLE_INT=3600

PARENT_REF_TIME=20190610060000

ENABLE_PARAM_USER=0     # 0: Do not enable the 'PARAM_USER' section of the SCALE namelist
                        # 1: Enable the 'PARAM_USER' section of the SCALE namelist (require 'config.nml.scale_user' and customized version of SCALE)

OCEAN_INPUT=0           # 0: No ocean input (use cycling ocean variables)
                        # 1: Update the ocean variables every cycle
OCEAN_FORMAT=99         # 0: SCALE init files (with exactly same domain settings; do not need additional preprocessing)
                        # 99: From the same file as used in generating the boundary conditions ($BDY_FORMAT)
LAND_INPUT=0            # 0: No land input (use cycling land variables)
                        # 1: Update the land variables every cycle
LAND_FORMAT=99          # 0: SCALE init files (with exactly same domain settings; do not need additional preprocessing)
                        # 99: From the same file as used in generating the boundary conditions ($BDY_FORMAT)

OBSNUM=1
OBSNAME[1]='radar'
nele=3
obselm[1]='ze'
obselm[2]='vr'
obselm[3]='qcf'

#===============================================================================
# PAWR decoder 

PAWR_DECODE=1
PAWR_RAW="$DATADIR/scale-letkf-test-suite/obs/PAWR_Kobe/raw"
FNAME_PAWR_RAW="obs.pawr<type>"
OBS="$INDIR/obs_letkf"

#===============================================================================
# Cycling settings

WINDOW_S=30     # SCALE forecast time when the assimilation window starts (second)
WINDOW_E=30     # SCALE forecast time when the assimilation window ends (second)
LCYCLE=30       # Length of a DA cycle (second)
LTIMESLOT=30     # Timeslot interval for 4D-LETKF (second)

#===============================================================================
# Parallelization settings

MEMBER=50         # Ensemble size

PPN=4              # Number of processes per node

THREADS=12          # Number of threads per process

SCALE_NP=16        # Number of processes to run SCALE

NNODES=$(( ( MEMBER + 1 ) * ( SCALE_NP / PPN ) ))


#===============================================================================
# Temporary directories to store runtime files

ONLINE_STGOUT=0             # Stage out right after each cycle (do not wait until the end of the job)?
                            #  0: No
                            #  1: Yes

#SYSNAME="$(basename $OUTDIR)"                # A unique name in the machine
TMPSUBDIR="scale-letkf_PAWR_Kobe"           # (used to identify multiple runs in the same time)

TMP="$DIR/tmp/$TMPSUBDIR" # Temporary directory shared among all nodes
TMPS="$DIR/tmp/$TMPSUBDIR"  # Temporary directory only on the server node
#TMPS="$TMP"  # Temporary directory only on the server node
TMPL="$TMP"

CLEAR_TMP=0                 # Clear temporary directories after the completion of job?
                            #  0: No
                            #  1: Yes

USE_LLIO_BIN=1   # Use LLIO-transfer for binary files ? (effective only on Fugaku) 
                 # 0: No 
                 # 1: Yes

USE_LLIO_DAT=1   # Use LLIO-transfer for shared data files ? (effective only on Fugaku) 
                 # 0: No 
                 # 1: Yes

USE_SPACK=0 # 1: Use spack in job scripts
            # 0: Not use spack in job scripts
            #    SCALE environment paramters (e.g., SCALE_NETCDF_C) should be exported

#===============================================================================
# Environmental settings

SCP='cp -L'
SCP_HOSTPREFIX=''

STAGE_THREAD=8
TAR_THREAD=8

PYTHON="python"

#BUFRBIN=

#===============================================================================
# Machine-independent source file

. ./config.rc

USE_INIT_FROM_BDY=1

#===============================================================================
