#!/bin/bash
#===============================================================================
#
#  Main settings for SCALE-LETKF scripts
#
#===============================================================================

DIR="$(cd "$(pwd)/.." && pwd)"   # Root directory of the GFS-LETKF
#DIR="/data1/gylien/letkf/scale"

OUTDIR="/data1/gylien/exp/test"  # Directory for GFS-LETKF output

LOGDIR="$DIR/log"

#===============================================================================
# Location of model/data files

MODELDIR="/data1/gylien/scale/scale-les/test/case_real/ctl_4_small_domain/run"
DATADIR="/data1/SCALE/database"

ANLWRF="/data1/SCALE/wrfout_10min"
ANLWRF_INT=600
#ANLGFS="/discover/nobackup/glien/model/CFSR_t62"         # directory of reference model files [sigma/surface formats]
#ANLGRD="/discover/nobackup/glien/model/CFSR_t62_grd"     # directory of reference model files [sigma-level grid format]
#ANLGRDP="/discover/nobackup/glien/model/CFSR_t62_grdp"   # directory of reference model files [pressure-level grid format]
#ANLGRDP2="/discover/nobackup/glien/model/EC_interim_t62_grdp" # directory of reference model files [pressure-level grid format]

#INITGFS="/discover/nobackup/glien/model/GDAS_IC_t62"     # directory of arbitrary initial condition files [sigma/surface formats]

OBS=              # directory of observation data in LETKF obs format
OBSNCEP=          # directory of observation data in NCEP BUFR format

#===============================================================================
# Temporary directories to store runtime files
#
# TMPDAT_MODE
# TMPRUN_MODE
# TMPOUT_MODE
#              1: share (link to TMP)
#              2: share (staging to TMP)
#              3: local (staging to TMPL)
#
# MACHINE_TYPE 1: Linux cluster with PBS
#              10: K-computer
#
# TMP    Temporary directory shared among all nodes
# TMPS   Temporary directory only on the server node
# TMPL   Local temporary directory on computing nodes

# STAGE_OPT ???

###### K computer
MACHINE_TYPE=1

SYSNAME="$(basename $OUTDIR)"    # A unique name in the machine
                                 # (used to identify multiple GFS-LETKFs running in the same time)
TMPSUBDIR="scale-letkf_$(whoami)_${SYSNAME}"

TMPDAT_MODE=3
TMPRUN_MODE=3
TMPOUT_MODE=$TMPRUN_MODE

TMP="$DIR/tmp/$TMPSUBDIR"
TMPS="/dev/shm/$TMPSUBDIR"
TMPL="/dev/shm/$TMPSUBDIR"


#-------------------

ONLINE_STGOUT=1  # 0: No
                 # 1: Yes

#===============================================================================
# Environmental settings

######
MPIBIN=$(dirname $(which mpirun))
MPIRUN="$MPIBIN/mpirun"
######

#SCP="scp -q"
#SCP_HOSTPREFIX="$PBS_O_HOST:"
SCP='cp -L'
SCP_HOSTPREFIX=''

PYTHON="python"

#BUFRBIN=/home/glien/pkg/BUFRLIB/bin

#===============================================================================
# Parallelization settings

MEMBER=2           # Ensemble size

NNODES=4           # Number of nodes
PPN=4              # Number of processes per node

THREADS=4           ######

                   # (This limit is usually due to available memory per node/core)
MIN_NP_SCALE=4     # Minimum number of cores required to run SCALE

                   # (This limit is usually due to parallelization efficiency)
MAX_NP_SCALE=4     # Maximum number of cores suggested to run SCALE

BGJOB_INT='0.1s'   # Interval of multiple background job submissions

#===============================================================================
# LETKF settings

WINDOW_S=300       # SCALE forecast time when assimilation window starts (second)
WINDOW_E=900       # SCALE forecast time when assimilation window ends (second)
LCYCLE=600         # Length of a GFS-LETKF cycle (second)
LTIMESLOT=60       # Timeslot interval for 4D-LETKF (second)
#LTIMESLOTMEAN=60   # Timeslot interval to compute ensemble mean for GSI QC and thinning (second)

FHMAX=$WINDOW_E    # GFS forecast length in a cycle (hour)
FHOUT=$LTIMESLOT   # GFS forecast output interval (hour)

#OBSOPE_OPT=1       # Observation operator options:
#                   #  1: use LETKF built-in obsope
#                   #  2: use GSI

#THIN_OPT=2         # Superobing/thinning options:
#                   # -- Options below (1-2) is for OBSOPE_OPT=1
#                   #  1: No superobing/thinning
#                   #  2: Use superobed/thinned observations
#                   #     Superobed/thinned observations store in $OUTDIR/obs/superob
#                   # -- Options below (3-4) are for OBSOPE_OPT=2
#                   #  3: use thinned observations for satellite radiance observations only
#                   #  4: use thinned observations for both conventional and satellite radiance observations

ADAPTINFL=1        # Adaptive inflation
                   #  0: OFF
                   #  1: ON, using inflation parameter 1 cycle  ago as prior
                   #  2: ON, using inflation parameter 2 cycles ago as prior

#===============================================================================
# Do not need to edit below...

#-------------------

SCALE_SFX='.pe%06d.nc'
SCALE_LOG_SFX='.pe000000'
MEMBER_FMT='%04d'

#-------------------

STAGING_DIR="$TMP/staging"
NODEFILE_DIR="$TMP/node"

if ((TMPDAT_MODE <= 2)); then
  TMPDAT="$TMP/dat"
else
  TMPDAT="$TMPL/dat"
fi
if ((TMPRUN_MODE <= 2)); then
  TMPRUN="$TMP/run"
else
  TMPRUN="$TMPL/run"
fi
if ((TMPOUT_MODE <= 2)); then
  TMPOUT="$TMP/out"
else
  TMPOUT="$TMPL/out"
fi

#------------------------

SCRP_DIR="$DIR/run"              # Job script directory
COMMON_DIR="$DIR/common"         # Common program directory
LETKF_DIR="$DIR/letkf"           # LETKF program directory
OBSUTIL_DIR="$DIR/obs"           # Observation program directory
VERIFY_DIR="$DIR/verify"         # Verification program directory
UTIL_DIR="$DIR/util"             # Other utility program directory

